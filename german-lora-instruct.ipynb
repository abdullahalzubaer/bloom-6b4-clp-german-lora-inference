{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2a30992-78b4-4535-a15a-699c3c74a252",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "from transformers import AutoModel, AutoTokenizer, BloomForCausalLM, GenerationConfig\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7afed1c-d82b-4707-9c86-bbd766ff086f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODEL = \"malteos/bloom-6b4-clp-german\"\n",
    "\n",
    "model_bloom= BloomForCausalLM.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    load_in_8bit=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    offload_folder=\"offload\",\n",
    ")\n",
    " \n",
    "tokenizer_bloom= AutoTokenizer.from_pretrained(BASE_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb979a07-443b-41e1-9657-71ad66dbe16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)/adapter_config.json: 100%|██████████| 395/395 [00:00<00:00, 69.2kB/s]\n",
      "Downloading adapter_model.bin: 100%|██████████| 31.5M/31.5M [00:01<00:00, 24.0MB/s]\n"
     ]
    }
   ],
   "source": [
    "model_peft_zubaer = PeftModel.from_pretrained(model_bloom, \"abdullahalzubaer/bloom-6b4-clp-german-instruct-lora-peft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a308d82-facf-465b-9c7d-8254031b4855",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)/adapter_config.json: 100%|██████████| 424/424 [00:00<00:00, 317kB/s]\n",
      "Downloading adapter_model.bin: 100%|██████████| 31.5M/31.5M [00:01<00:00, 23.9MB/s]\n"
     ]
    }
   ],
   "source": [
    "model_peft = PeftModel.from_pretrained(model_bloom, \"asprenger/bloom-6b4-clp-german-instruct-lora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7b2de96-2df3-4544-8efe-c18866244121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating...\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "### Instruction:\n",
      "What are the differences between alpacas and sheep?\n",
      "### Response: Alpakazüchter züchten die Wolle von Tieren, während Schafzüchter nur das Fleisch und den Dung des Tieres nutzen können; Sie haben auch unterschiedliche Körperformen mit einem längeren Hals für Schafe im Vergleich\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, GPTJForCausalLM, GenerationConfig\n",
    "\n",
    "PROMPT = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "### Instruction:\n",
    "What are the differences between alpacas and sheep?\n",
    "### Response:\"\"\"\n",
    "\n",
    "def generate_sth(text):\n",
    "    # https://colab.research.google.com/drive/1O1JjyGaC300BgSJoUbru6LuWAzRzEqCz?usp=sharing\n",
    "\n",
    "    inputs = tokenizer_bloom(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    input_ids = inputs[\"input_ids\"].cuda()\n",
    "\n",
    "    generation_config = GenerationConfig(\n",
    "        temperature=0,\n",
    "        top_p=1,\n",
    "        repetition_penalty=1.2,\n",
    "    )\n",
    "\n",
    "    print(\"Generating...\")\n",
    "    generation_output = model_peft_zubaer.generate(\n",
    "        input_ids=input_ids,\n",
    "        generation_config=generation_config,\n",
    "        return_dict_in_generate=True,\n",
    "        output_scores=True,\n",
    "        max_new_tokens=40,\n",
    "        pad_token_id = 0,\n",
    "        eos_token_id = 50256\n",
    "    )\n",
    "\n",
    "    for s in generation_output.sequences:\n",
    "        print(tokenizer_bloom.decode(s))\n",
    "generate_sth(PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e468691-4ddd-4fb6-a8d8-901ca9c6d6a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62de0c44875744beb69441c98f8347d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2e3547-dbda-4eb9-8c79-08e37bfd8817",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ca5a1b-be05-41b3-be32-925eafce5c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_peft.push_to_hub(\"abdullahalzubaer/bloom-6b4-clp-german-instruct-lora-peft\", use_auth_token=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:lora-peft0.2.0]",
   "language": "python",
   "name": "conda-env-lora-peft0.2.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
